# -*- coding: utf-8 -*-
"""AI - Medical Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G8uukfn4m-va_U_PsR41Y3VSD6F_RbG7
"""

!pip install spacy
!pip install spacy-transformers

!pip install scispacy
!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz

!pip install https://huggingface.co/kormilitzin/en_core_med7_trf/resolve/main/en_core_med7_trf-any-py3-none-any.whl

!pip install workcloud

from google.colab import files
uploaded = files.upload()

import io
text = io.BytesIO(uploaded['data1.txt']).read().decode("utf8")

cases = text.split('\n-----\n')
h, e, a = cases[0].split('\n\n')

a

import spacy
import scispacy
from nltk.corpus import wordnet as wn
import nltk

sci_nlp = spacy.load('en_ner_bc5cdr_md')
med7_nlp = spacy.load('en_core_med7_trf')
nltk.download('wordnet')
nltk.download('omw-1.4')

def get_drugs(h):
  data = {}
  h_ents = med7_nlp(h).ents
  for ent in h_ents:
    if ent.label_ == 'DRUG':
      label = 'DRUGS'
    else:
      continue
    
    if not data.get(label):
      data[label] = {ent.text}
    else:
      data[label].add(ent.text)
  return data

def get_meds(a):
  data = {}
  a_ents = med7_nlp(a).ents
  a
  for ent in a_ents:
    if ent.label_ == 'DRUG':
      label = 'MEDICATION'
    else:
      continue
    
    if not data.get(label):
      data[label] = {ent.text}
    else:
      data[label].add(ent.text)
  return data

!pip install nltk

def get_body_region(h, e, a):
  data = {}
  part = wn.synsets('body_part')[0]

  for word in (h+e+a).split(" "):
    for ss in wn.synsets(word):
        # only get those where the synset matches exactly
        name = ss.name().split(".", 1)[0]
        if name != word:
            continue
        hit = part.lowest_common_hypernyms(ss)
        print(hit, part)
        if hit and hit[0] == part:
          print(word)
          if word in ["right", "left"]:
            continue
          if not data.get("BODY REGIONS"):
            data["BODY REGIONS"] = {word}
          else:
            data["BODY REGIONS"].add(word)
        print(data)
  return data

!pip install negspacy
!pip install stanza
!pip install spacy-stanza

import stanza
import spacy_stanza
from negspacy.negation import Negex
from negspacy.negation import termset
from negspacy.termsets import termset

ts = termset("en_clinical")
ts.add_patterns({
            'preceding_negations': ['abstain from','other than','except for','except','with the exception of',
                                    'excluding','lack of','contraindication','contraindicated','interfere with',
                                   'prohibit','prohibits'],
            'following_negations':['negative','is allowed','impossible','exclusionary']
        })
sci_nlp = spacy.load("en_ner_bc5cdr_md")
sci_nlp.add_pipe("negex", config={"ent_types":["CHEMICAL","DISEASE"]})
tt_nlp=spacy_stanza.load_pipeline('en', package='mimic', processors={'ner': 'i2b2'})
tt_nlp.add_pipe("negex", config={"ent_types":["TEST",'TREATMENT']})
med7_nlp = spacy.load('en_core_med7_trf')

def get_symptoms(h):
  data = {}
  data["SYMPTOMS"] = set()
  h_ents = sci_nlp(h).ents
  for ent in h_ents:
    if ent.label_ == 'DISEASE':
      label = 'SYMPTOMS'
    else:
      continue
    data["SYMPTOMS"].add(ent.text)
  return data

def get_diagnosis(a):
  data = {"DIAGNOSIS": set(), "TEST": set(), "TREATMENT": set()}
  a_ents = sci_nlp(a).ents
  for ent in a_ents:
    if ent.label_ == 'DISEASE':
      label = 'DIAGNOSIS'
    else:
      label = ent.label_
    
    if not data.get(label):
      data[label] = {ent.text}
    else:
      data[label].add(ent.text)
  
  answer_doc_tt_nlp=tt_nlp(a)

  for e in answer_doc_tt_nlp.ents:
    if e.label_ == "PROBLEM":
      e.label_ = "DIAGNOSIS"
    if not e._.negex:
      data[e.label_].add(e.text)
  return data

texts = {}
for i, case in enumerate(cases):
  if not len(case.split("\n\n")) == 3:
    continue
  h, e, a = case.split("\n\n")
  texts[i] = {"History": h, "Examination": e, "Answer": a}

def get_age(h):
  # h = "A 23-year-old."
  age = ""
  for l in h:
    if l in '1234567890':
      age += l
    else:
      if age:
        break
  return age

def get_gender(history, nlp_sd):
  sex = nlp_sd.get_pipe('attribute_ruler')
  sex.add([[{"TEXT":"male"}],[{"TEXT":"man"}],[{"TEXT":"boy"}],[{"TEXT":"him"}],[{"TEXT":"he"}],[{"TEXT":"his"}]],{"LEMMA":"Male"})
  sex.add([[{"TEXT":"female"}],[{"TEXT":"woman"}],[{"TEXT":"girl"}],[{"TEXT":"her"}],[{"TEXT":"she"}]],{"LEMMA":"Female"})
  sex_doc = nlp_sd(history)
  gender =["Male","Female"]
  for token in sex_doc:
      if str(token.lemma_) in gender:
          return token.lemma_

patients = {}
for i, text in enumerate(texts.values()):
  patients[i] = {}
  h, e, a = text.values()
  age = get_age(h)
  gender = get_gender(h, sci_nlp)
  symptoms = get_symptoms(h)
  diagnosis = get_diagnosis(a)
  body_region = get_body_region(h, e, a)
  drugs = get_drugs(h)
  meds = get_meds(a)
  patients[i]["AGE"] = age
  patients[i]["GENDER"] = gender
  patients[i].update(symptoms)
  patients[i].update(diagnosis)
  patients[i].update(body_region)
  patients[i].update(drugs)
  patients[i].update(meds)
  patients[i].update(text)

patients

for i, item in patients.items():
  for k, v in item.items():
    if k in ["AGE", "GENDER", "History", "Examination", "Answer"]:
      patients[i][k] = "".join(v)
      continue
    patients[i][k] = list(v)

import json
with open("medical-cases.json", "w", encoding="utf8") as f:
  json.dump(texts, f, indent=4)

with open("medical-cases-data.json", "w", encoding="utf8") as f:
  json.dump(patients, f, indent=4)

